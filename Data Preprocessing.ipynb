{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Cancellation Notices handling**\n",
    "- Returns json files with info on the cancellation notices\n",
    "- can derive the predecessor of ADs from that as well"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6780d8a210e97a2b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "PDF_DIR = r\"C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\"\n",
    "# PDF_DIR = r\"C:\\Users\\zdrop\\PycharmProjects\\BRUMBRUMWEEEE\\Sample_of_a_sample\"\n",
    "OUTPUT_DIR = os.path.join(PDF_DIR, \"output\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def generate():\n",
    "    client = genai.Client(\n",
    "        vertexai=True,\n",
    "        project=\"mthesis-450913\",\n",
    "        location=\"us-central1\",\n",
    "    )\n",
    "\n",
    "    for filename in os.listdir(PDF_DIR):\n",
    "        if not filename.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "\n",
    "        pdf_path = os.path.join(PDF_DIR, filename)\n",
    "        print(f\"\\nProcessing: {filename}\")\n",
    "\n",
    "        # Load PDF\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            pdf_data = f.read()\n",
    "\n",
    "        # Instruction\n",
    "        instruction = types.Part.from_text(\n",
    "            text=\"\"\"From this cancellation notice, extract the following information: \n",
    "            - Cancelled AD (e.g., 2003-0208), one cancellation notice can cancel many ADs\n",
    "            - Replaced by (if mentioned, usually a different AD number)\n",
    "            - Reference publications (e.g., service bulletins or foreign ADs, without dates)\n",
    "            - Effective date (if available). The date in the documents could be in different formats, unify to YYYY-MM-DD\"\"\"\n",
    "        )\n",
    "\n",
    "        document = types.Part.from_bytes(\n",
    "            data=pdf_data,\n",
    "            mime_type=\"application/pdf\",\n",
    "        )\n",
    "\n",
    "        contents = [\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[instruction, document]\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Schema\n",
    "        generate_content_config = types.GenerateContentConfig(\n",
    "            temperature=0.3,\n",
    "            top_p=0.95,\n",
    "            max_output_tokens=2048,\n",
    "            response_modalities=[\"TEXT\"],\n",
    "            safety_settings=[\n",
    "                types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "                types.SafetySetting(category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "                types.SafetySetting(category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "                types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "            ],\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"cancelled_ad\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The AD number(s) that this document cancels (e.g., 2010-0132)\"\n",
    "                    },\n",
    "                    \"replaced_by\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"nullable\": True,\n",
    "                        \"description\": \"The AD number that replaces the cancelled AD, if mentioned\"\n",
    "                    },\n",
    "                    \"reference_publications\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"effective_date\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"format\": \"date\",\n",
    "                        \"nullable\": True,\n",
    "                        \"description\": \"The effective date of the cancellation if available (e.g., 2023-08-15)\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"cancelled_ad\"],\n",
    "                \"propertyOrdering\": [\n",
    "                    \"cancelled_ad\",\n",
    "                    \"replaced_by\",\n",
    "                    \"reference_publications\",\n",
    "                    \"effective_date\"\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Call Gemini and collect response\n",
    "        result_text = \"\"\n",
    "        for chunk in client.models.generate_content_stream(\n",
    "            model=\"gemini-2.0-flash-lite-001\",\n",
    "            contents=contents,\n",
    "            config=generate_content_config,\n",
    "        ):\n",
    "            result_text += chunk.text\n",
    "\n",
    "        # Parse and save JSON\n",
    "        try:\n",
    "            parsed = json.loads(result_text)\n",
    "            output_path = os.path.join(OUTPUT_DIR, f\"{os.path.splitext(filename)[0]}.json\")\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as out_file:\n",
    "                json.dump(parsed, out_file, indent=2)\n",
    "            print(f\"✅ Saved to {output_path}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"❌ Failed to parse JSON for {filename}\")\n",
    "            print(result_text)\n",
    "\n",
    "generate()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f948d7544b390b8c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Removing non-english files**\n",
    "- put all files in a separate directory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63b8397277e871f0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langdetect import detect\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "source_dir = r\"C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A320\"\n",
    "non_english_dir = os.path.join(source_dir,r\"C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\non_english\")\n",
    "char_threshold = 1000  # Number of characters to use for detection\n",
    "\n",
    "# Create target folder if it doesn't exist\n",
    "os.makedirs(non_english_dir, exist_ok=True)\n",
    "\n",
    "# === FUNCTION TO EXTRACT TEXT FROM PDF ===\n",
    "def extract_text(pdf_path, max_chars=1000):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "            if len(text) >= max_chars:\n",
    "                break\n",
    "        return text[:max_chars]\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        file_path = os.path.join(source_dir, filename)\n",
    "        sample_text = extract_text(file_path)\n",
    "\n",
    "        if not sample_text.strip():\n",
    "            print(f\"Skipping (empty or unreadable): {filename}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            lang = detect(sample_text)\n",
    "            if lang != \"en\":\n",
    "                print(f\"Detected {lang} – moving: {filename}\")\n",
    "                shutil.move(file_path, os.path.join(non_english_dir, filename))\n",
    "            else:\n",
    "                print(f\"Detected English – keeping: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Language detection failed for {filename}: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26ee021bf8ad36fd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Updated cancellation notices handling - input in json**\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34b65dff45bcd857"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: AD_2010-0083-CN_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_2010-0083-CN_1_extracted.json\n",
      "\n",
      "Processing: AD_2010-0132-CN_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_2010-0132-CN_1_extracted.json\n",
      "\n",
      "Processing: AD_2013-0251-CN_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_2013-0251-CN_1_extracted.json\n",
      "\n",
      "Processing: AD_2014-0257-CN_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_2014-0257-CN_1_extracted.json\n",
      "\n",
      "Processing: AD_2016-0065-CN_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_2016-0065-CN_1_extracted.json\n",
      "\n",
      "Processing: AD_2018-0034-CN_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_2018-0034-CN_1_extracted.json\n",
      "\n",
      "Processing: AD_2018-0226-CN_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_2018-0226-CN_1_extracted.json\n",
      "\n",
      "Processing: AD_2020-0190-CN_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_2020-0190-CN_1_extracted.json\n",
      "\n",
      "Processing: AD_2020-0273-CN_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_2020-0273-CN_1_extracted.json\n",
      "\n",
      "Processing: AD_2021-0180-CN_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_2021-0180-CN_1_extracted.json\n",
      "\n",
      "Processing: AD_F-2002-529R1_2.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2002-529R1_2_extracted.json\n",
      "\n",
      "Processing: AD_F-2002-548R2_2.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2002-548R2_2_extracted.json\n",
      "\n",
      "Processing: AD_F-2003-020R1_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2003-020R1_1_extracted.json\n",
      "\n",
      "Processing: AD_F-2003-121R1_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2003-121R1_1_extracted.json\n",
      "\n",
      "Processing: AD_F-2003-213R2_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2003-213R2_1_extracted.json\n",
      "\n",
      "Processing: AD_F-2003-371R1_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2003-371R1_1_extracted.json\n",
      "\n",
      "Processing: AD_F-2003-373R1_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2003-373R1_1_extracted.json\n",
      "\n",
      "Processing: AD_F-2003-407R1_2.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2003-407R1_2_extracted.json\n",
      "\n",
      "Processing: AD_F-2003-458R1_2.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2003-458R1_2_extracted.json\n",
      "\n",
      "Processing: AD_F-2004-011R1_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2004-011R1_1_extracted.json\n",
      "\n",
      "Processing: AD_F-2004-024_3.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2004-024_3_extracted.json\n",
      "\n",
      "Processing: AD_F-2004-080R1_2.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2004-080R1_2_extracted.json\n",
      "\n",
      "Processing: AD_F-2004-086R2_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2004-086R2_1_extracted.json\n",
      "\n",
      "Processing: AD_F-2004-112R1_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2004-112R1_1_extracted.json\n",
      "\n",
      "Processing: AD_F-2004-195R1_1.json\n",
      "✅ Saved to C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\\output_structured\\AD_F-2004-195R1_1_extracted.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# This directory should now contain your JSON files with the raw text.\n",
    "INPUT_DIR = r\"C:\\Users\\zdrop\\OneDrive - TU Wien\\MASTER THESIS\\ADs\\A330\\cancellation_notices\\output_json_files\"\n",
    "# INPUT_DIR = r\"C:\\Users\\zdrop\\PycharmProjects\\BRUMBRUMWEEEE\\Sample_of_a_sample\"\n",
    "OUTPUT_DIR = os.path.join(INPUT_DIR, \"output_structured\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def generate():\n",
    "    \"\"\"\n",
    "    Processes JSON files containing raw text, extracts structured data using the Gemini API,\n",
    "    and saves the results as new JSON files.\n",
    "    \"\"\"\n",
    "    client = genai.Client(\n",
    "        vertexai=True,\n",
    "        project=\"mthesis-450913\",\n",
    "        location=\"us-central1\",\n",
    "    )\n",
    "\n",
    "    for filename in os.listdir(INPUT_DIR):\n",
    "        # Process only .json files\n",
    "        if not filename.lower().endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        input_path = os.path.join(INPUT_DIR, filename)\n",
    "        print(f\"\\nProcessing: {filename}\")\n",
    "\n",
    "        # Load the JSON file and extract the raw text from the \"text\" key\n",
    "        try:\n",
    "            with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                raw_text = data.get(\"text\") # Get text from the JSON object\n",
    "                if not raw_text:\n",
    "                    print(f\"⚠️  Skipping {filename}: No 'text' key found or content is empty.\")\n",
    "                    continue\n",
    "        except (json.JSONDecodeError, IOError) as e:\n",
    "            print(f\"❌ Error reading or parsing {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Instruction for the model\n",
    "        instruction = types.Part.from_text(\n",
    "            text=\"\"\"From this cancellation notice, extract the following information: \n",
    "            - Cancelled AD (e.g., 2003-0208), one cancellation notice can cancel many ADs\n",
    "            - Replaced by (if mentioned, usually a different AD number)\n",
    "            - Reference publications (e.g., service bulletins or foreign ADs, without dates)\n",
    "            - Effective date (if available). The date in the documents could be in different formats, unify to YYYY-MM-DD\"\"\"\n",
    "        )\n",
    "        \n",
    "        # Create the document part from the extracted raw text\n",
    "        document = types.Part.from_text(text=raw_text)\n",
    "\n",
    "        contents = [\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[instruction, document]\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Define the generation configuration and the desired JSON output schema\n",
    "        generate_content_config = types.GenerateContentConfig(\n",
    "            temperature=0.3,\n",
    "            top_p=0.95,\n",
    "            max_output_tokens=2048,\n",
    "            response_modalities=[\"TEXT\"],\n",
    "            safety_settings=[\n",
    "                types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "                types.SafetySetting(category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "                types.SafetySetting(category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "                types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "            ],\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"cancelled_ad\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The AD number(s) that this document cancels (e.g., 2010-0132)\"\n",
    "                    },\n",
    "                    \"replaced_by\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"nullable\": True,\n",
    "                        \"description\": \"The AD number that replaces the cancelled AD, if mentioned\"\n",
    "                    },\n",
    "                    \"reference_publications\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"effective_date\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"format\": \"date\",\n",
    "                        \"nullable\": True,\n",
    "                        \"description\": \"The effective date of the cancellation if available (e.g., 2023-08-15)\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"cancelled_ad\"],\n",
    "                \"propertyOrdering\": [\n",
    "                    \"cancelled_ad\",\n",
    "                    \"replaced_by\",\n",
    "                    \"reference_publications\",\n",
    "                    \"effective_date\"\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Call Gemini and collect the streaming response\n",
    "        result_text = \"\"\n",
    "        try:\n",
    "            for chunk in client.models.generate_content_stream(\n",
    "                model=\"gemini-2.0-flash-lite-001\",\n",
    "                contents=contents,\n",
    "                config=generate_content_config,\n",
    "            ):\n",
    "                result_text += chunk.text\n",
    "        except Exception as e:\n",
    "            print(f\"❌ An error occurred during API call for {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Parse the JSON response and save it to a file\n",
    "        try:\n",
    "            parsed = json.loads(result_text)\n",
    "            output_filename = f\"{os.path.splitext(filename)[0]}_extracted.json\"\n",
    "            output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as out_file:\n",
    "                json.dump(parsed, out_file, indent=2)\n",
    "            print(f\"✅ Saved to {output_path}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"❌ Failed to parse JSON response for {filename}\")\n",
    "            print(\"--- Model Output ---\")\n",
    "            print(result_text)\n",
    "            print(\"--------------------\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-11T13:50:22.853631200Z",
     "start_time": "2025-06-11T13:49:55.025745100Z"
    }
   },
   "id": "9f44ab47891f6449",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4900970d6589645e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
